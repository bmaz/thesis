\chapter*{Synthèse en français}
\addcontentsline{toc}{chapter}{Synthèse en français}

Cette thèse se donne pour objectif d'étudier le rôle de Twitter dans l'évolution de la production d'information médiatique au cours des dernières années. Notre objectif est de découvrir dans quelle mesure les histoires (que nous désignons en anglais par \textit{stories} ou \textit{events}) populaires sur les réseaux sociaux sont davantage relayés par les médias traditionnels. Le défi est de quantifier et d'analyser précisément les relations entre les deux sphères, dans un contexte de très forte dépendance de chaque sphère vis-à-vis de l'autre. Cette synthèse détaille l'ensemble des étapes nécessaires pour y parvenir.

\section*{Construire un corpus pour la détection d'événements sur Twitter}
Nous proposons tout d'abord une nouvelle méthode pour collecter un grand volume de tweets aléatoires. En effet, l'API \textit{Sample} de Twitter ne donne accès qu'à 1\% de l'ensemble des tweets émis à un moment donné. Notre méthode est fondée sur une autre API, \textit{Filter}, avec pour paramètres de recherche les mots les plus fréquents d'une langue donnée. Nous montrons que la distribution des mots dans le corpus ainsi collecté est extrêmement similaire à celle obtenue avec l'API \textit{Sample} de Twitter, prouvant ainsi que notre méthode permet d'obtenir un échantillon aléatoire de l'ensemble des tweets émis. De plus, nous montrons que pour un ensemble de mots et un certain nombre de clefs d'accès à Twitter, grouper les termes qui sont fréquemment employés ensemble sur la même clef d'accès à l'API donne de meilleurs résultats que de répartir aléatoirement les mots sur chaque clef d'accès.

Notre méthode nous a permis de collecter environ 5 millions de tweets par jour sans discontinuer depuis juin 2018. Nous estimons, en comparant notre jeu de données à d'autres corpus collectés par des chercheurs français dans la période, que nous collectons entre 60\% et 75\% de tous les tweets en français émis sur Twitter, et entre 74\% et 78\% de tous les tweets originaux (c'est-à-dire en excluant les retweets).

Enfin, nous présentons un corpus permettant d'évaluer la performance des algorithmes de détection d'événements dans les tweets, composé de plus de 95000 tweets annotés manuellement. Ce corpus, ainsi que le code de nos expériences de détection d'événements, est désormais accessible publiquement afin de servir de référence pour comparer de nouveaux algorithmes. Nous publions également les identifiants de tous les tweets originaux collectés pendant les trois semaines d'annotation (38 millions de tweets). Ce très grand volume de tweets peut également servir à entraîner des modèles de langue.

\section*{Détecter les événements sur Twitter}
Nous introduisons une version ``mini batch" de l'algorithme \textit{First Story Detection} (FSD) \citep{allan_introduction_2002} qui surpasse largement le modèle \textit{Dirichlet Multinomial Mixture }(DMM) \citep{yin_dirichlet_2014} pour la tâche de détection d'événements sur deux jeux de données différents. L'algorithme FSD prend en entrée des représentations vectorielles de documents (à l'origine des vecteurs tf-idf), qui sont ensuite regroupés en fonction de leur similarité cosinus. Les mini-batchs permettent d'accélérer l'algorithme dans le cas de vecteurs creux tels que les vecteurs tf-idf, du fait des propriétés de la multiplication de matrices creuses. 

Nous comparons également le gain qu'apportent différents modèles de plongements sémantiques de phrases/textes courts à l'algorithme FSD. Parmi ces modèles, on trouve ELMo \citep{peters2018deep}, Universal Sentence Encoder \citep{cer2018universal}, BERT \citep{devlin2018bert} et Sentence-BERT \citep{reimers_2019_sentence}. Nous montrons que ces représentations de tweets ne font pas mieux que les traditionnels vecteurs tf-idf pour le clustering de tweets. Des représentations texte-image naïves fondées sur la concaténation des vecteurs (pour les vecteurs images, nous testons les modèles SIFT \citep{lowe1999object} et ResNet \citep{he2016deep}) ne permettent pas non plus d'améliorer les résultats.

Enfin, partant du constat que l'algorithme FSD standard n'est pas prévu pour filtrer les tweets trop courts ou qui contiennent des mots trop communs pour être discriminants, nous introduisons une nouvelle variante de cet algorithme pour rendre les clusters plus stables. Notre variante exclut certains tweets de la recherche de plus proche voisin. Elle permet à la fois de diminuer le temps de calcul, et d'améliorer la précision et le rappel par rapport au simple ``mini batch" FSD, lors de nos tests sur le corpus de 38 millions de tweets.

\section*{Lier les événements Twitter et les évenements médiatiques}

Notre approche pour regrouper les événements est fondée sur la détection de communautés dans le graphe pondéré de la similarité entre événements Twitter et événements médiatiques. Différentes combinaisons linéaires de mesures de similarité (similarité textuelle, nombre de hashtags en commun, nombre d'URLs en commun) sont testées, sur différents sous-ensembles de notre corpus. Nous montrons que l'approche la plus simple est de conserver uniquement la similarité textuelle sur les arêtes du graphe. Cette approche est également la plus robuste aux changements d'échantillon de test. Nous montrons également qu'introduire une contrainte temporelle pour supprimer les arêtes entres des événements trop éloignés dans le temps améliore la performance de notre méthode.

\section*{Réseaux sociaux et décisions éditoriales}
Enfin, afin de répondre à notre question de recherche, nous appliquons les algorithmes présentés ci-dessus à un corpus de tweets et de pages web de médias collectés entre juillet 2018 et juillet 2019 (1,8 milliards de tweets, 4 millions de pages web). Pour les événements joints qui ont commencé sur Twitter (c'est-à-dire que le premier document de l'événement joint est un tweet) nous étudions si la popularité des événements Twitter a une influence sur la couverture de l'événement par les médias traditionnels.

Nous menons une analyse en termes de variable instrumentale, standard en économétrie, pour isoler l'effet causal de la popularité Twitter d'une histoire sur sa couverture par les médias traditionnels. Notre contribution réside dans le choix d'une variable, qui soit à la fois tout à fait indépendante des choix éditoriaux des médias traditionnels, et qui ait un effet sur la popularité d'un événement sur Twitter. La variable choisie mesure l'interaction entre la centralité des utilisateurs dans le réseau social et la pression médiatique à un moment donné. La centralité de l'auteur du premier tweet de l'événement est estimée par le nombre de likes, retweets et citations de ses tweets avant le début de l'événement. La pression médiatique est mesurée par le nombre de likes, retweets et citations dans l'ensemble du jeu de données dans l'heure qui précède l'événement.

Nous montrons que la popularité d'un événement a un effet positif sur la couverture par les médias traditionnels, mais que cet effet varie en fonction des caractéristiques du média: l'effet est plus important pour les sites des télévisions que pour les sites de la presse quotidienne nationale, et il est également plus fort pour les médias dont les journalistes sont nombreux à avoir un compte Twitter. À l'inverse, nous n'observons pas d'effet significatif des types de revenus (certains médias dépendent uniquement des revenus publicitaires, d'autres protègent l'accès à leur page par un paywall qui incite les lecteurs à s'abonner). Ces résultats jettent un nouvel éclairage sur notre compréhension des décisions éditoriales à l'heure des réseaux sociaux.